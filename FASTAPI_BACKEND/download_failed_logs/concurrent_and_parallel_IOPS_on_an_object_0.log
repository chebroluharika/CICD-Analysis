2025-04-14 23:55:31,369 - cephci - log:161 - DEBUG - Completed log configuration
2025-04-14 23:55:31,371 - cephci - run:722 - INFO - Running test test_object_ops.py
2025-04-14 23:55:31,371 - cephci - test_object_ops:30 - INFO - 
    # CEPH-83571710
    Test to verify concurrent IOPs on an object in a pool
    1. Create a replicated pool
    2. Perform the below two tasks concurrently:
        - Use rados put to write 1MB data to an object (object size/2) times
          with initial offset 0 and incremental offset of 2MB from client node
        - Use rados put to write 1MB data to an object (object size/2) times
          with initial offset 1MB and incremental offset of 2MB from installer node
    3. Perform the below two tasks parallely:
        - Use rados put to write 1MB data to an object (object size/2) times
          with initial offset 0 and incremental offset of 2MB from client node
        - Use rados put to write 4MB data to an object 15 (object size/2) times
          with initial offset 4MB and incremental offset of 8MB from installer node
    4. Verify the ceph df stats and ensure the pool has only 1 object
        and stored data is equal to input Object size
    5. Delete the created pools
    
2025-04-14 23:55:31,372 - cephci - test_object_ops:36 - INFO - Running test case to verify parallel I/O operations on an Object
2025-04-14 23:55:31,372 - cephci - test_object_ops:46 - INFO - ----- Starting workflow for Concurrent IOPS -----

2025-04-14 23:55:31,372 - cephci - core_workflows:563 - DEBUG - creating pool_name re_pool_concurrent_io
2025-04-14 23:55:31,373 - cephci - ceph:1576 - INFO - Execute cephadm shell -- ceph osd pool create re_pool_concurrent_io on 10.0.195.177
2025-04-14 23:55:34,491 - cephci - ceph:1606 - INFO - Execution of cephadm shell -- ceph osd pool create re_pool_concurrent_io on 10.0.195.177 took 3.117838 seconds
2025-04-14 23:55:34,492 - cephci - shell:64 - DEBUG - 
2025-04-14 23:55:34,494 - cephci - ceph:1576 - INFO - Execute cephadm shell -- sudo ceph osd pool application enable re_pool_concurrent_io rados on 10.0.195.177
2025-04-14 23:55:37,871 - cephci - ceph:1606 - INFO - Execution of cephadm shell -- sudo ceph osd pool application enable re_pool_concurrent_io rados on 10.0.195.177 took 3.376946 seconds
2025-04-14 23:55:37,872 - cephci - shell:64 - DEBUG - 
2025-04-14 23:55:42,877 - cephci - core_workflows:620 - INFO - Created pool re_pool_concurrent_io successfully
2025-04-14 23:55:42,878 - cephci - test_object_ops:53 - INFO - Object size needs to be multiple of 2 for parallel writes, Input object size has been changed to 44
2025-04-14 23:55:42,880 - cephci - ceph:1576 - INFO - Execute truncate -s 1M ~/sample_1M on 10.0.195.177
2025-04-14 23:55:43,885 - cephci - ceph:1606 - INFO - Execution of truncate -s 1M ~/sample_1M on 10.0.195.177 took 1.004437 seconds
2025-04-14 23:55:43,889 - cephci - ceph:1576 - INFO - Execute truncate -s 1M /mnt/sample_1M on 10.0.195.201
2025-04-14 23:55:44,895 - cephci - ceph:1606 - INFO - Execution of truncate -s 1M /mnt/sample_1M on 10.0.195.201 took 1.004554 seconds
2025-04-14 23:55:44,900 - cephci - ceph:1576 - INFO - Execute cephadm shell  --mount ~/sample_1M -- rados put -p re_pool_concurrent_io obj_parallel_io_44 /mnt/sample_1M --offset 1048576 on 10.0.195.177
2025-04-14 23:55:44,900 - cephci - ceph:1576 - INFO - Execute rados put -p re_pool_concurrent_io obj_parallel_io_44 /mnt/sample_1M --offset 0 on 10.0.195.201
2025-04-15 00:00:45,240 - cephci - ceph:1632 - ERROR - rados put -p re_pool_concurrent_io obj_parallel_io_44 /mnt/sample_1M --offset 0 failed to execute within 300s.
2025-04-15 00:05:45,906 - cephci - ceph:1628 - ERROR - cephadm shell  --mount ~/sample_1M -- rados put -p re_pool_concurrent_io obj_parallel_io_44 /mnt/sample_1M --offset 1048576 failed to execute within 600 seconds.
2025-04-15 00:05:47,515 - cephci - test_object_ops:101 - ERROR - Failed with exception: None
2025-04-15 00:05:47,515 - cephci - test_object_ops:102 - ERROR - Command exceed the allocated execution time.
Traceback (most recent call last):
  File "/home/jenkins/ceph-builds/openstack/IBM/8.1/rhel-9/Regression/19.2.1-126/rados/99/cephci/ceph/ceph.py", line 1603, in long_running
    check_timeout(_end_time, timeout)
  File "/home/jenkins/ceph-builds/openstack/IBM/8.1/rhel-9/Regression/19.2.1-126/rados/99/cephci/ceph/ceph.py", line 1157, in check_timeout
    raise TimeoutException("Command exceed the allocated execution time.")
ceph.ceph.TimeoutException: Command exceed the allocated execution time.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jenkins/ceph-builds/openstack/IBM/8.1/rhel-9/Regression/19.2.1-126/rados/99/cephci/tests/rados/test_object_ops.py", line 62, in run
    else rados_obj.run_concurrent_io(
  File "/home/jenkins/ceph-builds/openstack/IBM/8.1/rhel-9/Regression/19.2.1-126/rados/99/cephci/ceph/rados/core_workflows.py", line 2963, in run_concurrent_io
    p.spawn(rados_put_installer)
  File "/home/jenkins/ceph-builds/openstack/IBM/8.1/rhel-9/Regression/19.2.1-126/rados/99/cephci/ceph/parallel.py", line 131, in __exit__
    self._results.append(_f.result())
  File "/usr/lib64/python3.9/concurrent/futures/_base.py", line 439, in result
    return self.__get_result()
  File "/usr/lib64/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
  File "/usr/lib64/python3.9/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/jenkins/ceph-builds/openstack/IBM/8.1/rhel-9/Regression/19.2.1-126/rados/99/cephci/ceph/rados/core_workflows.py", line 2958, in rados_put_client
    self.client.exec_command(sudo=True, cmd=client_put_cmd, check_ec=False)
  File "/home/jenkins/ceph-builds/openstack/IBM/8.1/rhel-9/Regression/19.2.1-126/rados/99/cephci/ceph/ceph.py", line 1668, in exec_command
    _out, _err, _exit, _time = self.long_running(**kw)
  File "/home/jenkins/ceph-builds/openstack/IBM/8.1/rhel-9/Regression/19.2.1-126/rados/99/cephci/ceph/ceph.py", line 1633, in long_running
    raise CommandFailed(tex)
ceph.ceph.CommandFailed: Command exceed the allocated execution time.
2025-04-15 00:05:47,517 - cephci - test_object_ops:105 - INFO - 
 
 ************** Execution of finally block begins here *************** 
 

2025-04-15 00:05:47,519 - cephci - ceph:1576 - INFO - Execute ceph config set mon mon_allow_pool_delete true on 10.0.195.201
2025-04-15 00:05:48,524 - cephci - ceph:1606 - INFO - Execution of ceph config set mon mon_allow_pool_delete true on 10.0.195.201 took 1.004612 seconds
2025-04-15 00:05:48,526 - cephci - ceph:1576 - INFO - Execute ceph df -f json on 10.0.195.201
2025-04-15 00:05:49,531 - cephci - ceph:1606 - INFO - Execution of ceph df -f json on 10.0.195.201 took 1.003988 seconds
2025-04-15 00:05:49,532 - cephci - ceph:1576 - INFO - Execute cephadm shell -- ceph osd pool ls detail -f json on 10.0.195.177
2025-04-15 00:05:51,042 - cephci - ceph:1606 - INFO - Execution of cephadm shell -- ceph osd pool ls detail -f json on 10.0.195.177 took 1.508631 seconds
2025-04-15 00:05:51,043 - cephci - ceph:1186 - DEBUG - 
2025-04-15 00:05:51,043 - cephci - ceph:1186 - DEBUG - [{"pool_id":1,"pool_name":".smb","create_time":"2025-04-14T22:21:53.425433+0000","flags":1,"flags_names":"hashpspool","type":1,"size":3,"min_size":2,"crush_rule":0,"peering_crush_bucket_count":0,"peering_crush_bucket_target":0,"peering_crush_bucket_barrier":0,"peering_crush_bucket_mandatory_member":2147483647,"is_stretch_pool":false,"object_hash":2,"pg_autoscale_mode":"on","pg_num":32,"pg_placement_num":32,"pg_placement_num_target":32,"pg_num_target":32,"pg_num_pending":32,"last_pg_merge_meta":{"source_pgid":"0.0","ready_epoch":0,"last_epoch_started":0,"last_epoch_clean":0,"source_version":"0'0","target_version":"0'0"},"last_change":"134","last_force_op_resend":"0","last_force_op_resend_prenautilus":"0","last_force_op_resend_preluminous":"52","auid":0,"snap_mode":"selfmanaged","snap_seq":0,"snap_epoch":0,"pool_snaps":[],"removed_snaps":"[]","quota_max_bytes":0,"quota_max_objects":0,"tiers":[],"tier_of":-1,"read_tier":-1,"write_tier":-1,"cache_mode":"none","target_max_bytes":0,"target_max_objects":0,"cache_target_dirty_ratio_micro":400000,"cache_target_dirty_high_ratio_micro":600000,"cache_target_full_ratio_micro":800000,"cache_min_flush_age":0,"cache_min_evict_age":0,"erasure_code_profile":"","hit_set_params":{"type":"none"},"hit_set_period":0,"hit_set_count":0,"use_gmt_hitset":true,"min_read_recency_for_promote":0,"min_write_recency_for_promote":0,"hit_set_grade_decay_rate":0,"hit_set_search_last_n":0,"grade_table":[],"stripe_width":0,"expected_num_objects":0,"fast_read":false,"options":{},"application_metadata":{"smb":{}},"read_balance":{"score_type":"Fair distribution","score_acting":4.25,"score_stable":4.25,"optimal_score":0.52999997138977051,"raw_score_acting":2.25,"raw_score_stable":2.25,"primary_affinity_weighted":1,"average_primary_affinity":1,"average_primary_affinity_weighted":1}},{"pool_id":2,"pool_name":".mgr","create_time":"2025-04-14T22:36:25.003390+0000","flags":1,"flags_names":"hashpspool","type":1,"size":3,"min_size":2,"crush_rule":0,"peering_crush_bucket_count":0,"peering_crush_bucket_target":0
2025-04-15 00:05:51,044 - cephci - ceph:1186 - DEBUG - ,"peering_crush_bucket_barrier":0,"peering_crush_bucket_mandatory_member":2147483647,"is_stretch_pool":false,"object_hash":2,"pg_autoscale_mode":"on","pg_num":1,"pg_placement_num":1,"pg_placement_num_target":1,"pg_num_target":1,"pg_num_pending":1,"last_pg_merge_meta":{"source_pgid":"0.0","ready_epoch":0,"last_epoch_started":0,"last_epoch_clean":0,"source_version":"0'0","target_version":"0'0"},"last_change":"37","last_force_op_resend":"0","last_force_op_resend_prenautilus":"0","last_force_op_resend_preluminous":"0","auid":0,"snap_mode":"selfmanaged","snap_seq":0,"snap_epoch":0,"pool_snaps":[],"removed_snaps":"[]","quota_max_bytes":0,"quota_max_objects":0,"tiers":[],"tier_of":-1,"read_tier":-1,"write_tier":-1,"cache_mode":"none","target_max_bytes":0,"target_max_objects":0,"cache_target_dirty_ratio_micro":400000,"cache_target_dirty_high_ratio_micro":600000,"cache_target_full_ratio_micro":800000,"cache_min_flush_age":0,"cache_min_evict_age":0,"erasure_code_profile":"","hit_set_params":{"type":"none"},"hit_set_period":0,"hit_set_count":0,"use_gmt_hitset":true,"min_read_recency_for_promote":0,"min_write_recency_for_promote":0,"hit_set_grade_decay_rate":0,"hit_set_search_last_n":0,"grade_table":[],"stripe_width":0,"expected_num_objects":0,"fast_read":false,"options":{"pg_num_max":32,"pg_num_min":1},"application_metadata":{"mgr":{}},"read_balance":{"score_type":"Fair distribution","score_acting":15.380000114440918,"score_stable":15.380000114440918,"optimal_score":0.12999999523162842,"raw_score_acting":2,"raw_score_stable":2,"primary_affinity_weighted":1,"average_primary_affinity":1,"average_primary_affinity_weighted":1}},{"pool_id":3,"pool_name":"cephfs.cephfs.meta","create_time":"2025-04-14T22:39:36.706636+0000","flags":1,"flags_names":"hashpspool","type":1,"size":3,"min_size":2,"crush_rule":0,"peering_crush_bucket_count":0,"peering_crush_bucket_target":0,"peering_crush_bucket_barrier":0,"peering_crush_bucket_mandatory_member":2147483647,"is_stretch_pool":false,"object_hash":2,"pg_autoscale_mode":"on","pg_num":16,"pg_pl
2025-04-15 00:05:51,045 - cephci - ceph:1186 - DEBUG - acement_num":16,"pg_placement_num_target":16,"pg_num_target":16,"pg_num_pending":16,"last_pg_merge_meta":{"source_pgid":"0.0","ready_epoch":0,"last_epoch_started":0,"last_epoch_clean":0,"source_version":"0'0","target_version":"0'0"},"last_change":"241","last_force_op_resend":"0","last_force_op_resend_prenautilus":"0","last_force_op_resend_preluminous":"85","auid":0,"snap_mode":"selfmanaged","snap_seq":0,"snap_epoch":0,"pool_snaps":[],"removed_snaps":"[]","quota_max_bytes":0,"quota_max_objects":0,"tiers":[],"tier_of":-1,"read_tier":-1,"write_tier":-1,"cache_mode":"none","target_max_bytes":0,"target_max_objects":0,"cache_target_dirty_ratio_micro":400000,"cache_target_dirty_high_ratio_micro":600000,"cache_target_full_ratio_micro":800000,"cache_min_flush_age":0,"cache_min_evict_age":0,"erasure_code_profile":"","hit_set_params":{"type":"none"},"hit_set_period":0,"hit_set_count":0,"use_gmt_hitset":true,"min_read_recency_for_promote":0,"min_write_recency_for_promote":0,"hit_set_grade_decay_rate":0,"hit_set_search_last_n":0,"grade_table":[],"stripe_width":0,"expected_num_objects":0,"fast_read":false,"options":{"pg_autoscale_bias":4,"pg_num_min":16,"recovery_priority":5},"application_metadata":{"cephfs":{"metadata":"cephfs"}},"read_balance":{"score_type":"Fair distribution","score_acting":3.7200000286102295,"score_stable":3.7200000286102295,"optimal_score":0.4699999988079071,"raw_score_acting":1.75,"raw_score_stable":1.75,"primary_affinity_weighted":1,"average_primary_affinity":1,"average_primary_affinity_weighted":1}},{"pool_id":4,"pool_name":"cephfs.cephfs.data","create_time":"2025-04-14T22:39:37.727542+0000","flags":131073,"flags_names":"hashpspool,bulk","type":1,"size":3,"min_size":2,"crush_rule":0,"peering_crush_bucket_count":0,"peering_crush_bucket_target":0,"peering_crush_bucket_barrier":0,"peering_crush_bucket_mandatory_member":2147483647,"is_stretch_pool":false,"object_hash":2,"pg_autoscale_mode":"on","pg_num":512,"pg_placement_num":512,"pg_placement_num_target":512,"pg_num_target":512,"pg_num_pending":512,"last_
2025-04-15 00:05:51,045 - cephci - ceph:1186 - DEBUG - pg_merge_meta":{"source_pgid":"0.0","ready_epoch":0,"last_epoch_started":0,"last_epoch_clean":0,"source_version":"0'0","target_version":"0'0"},"last_change":"176","last_force_op_resend":"0","last_force_op_resend_prenautilus":"0","last_force_op_resend_preluminous":"174","auid":0,"snap_mode":"selfmanaged","snap_seq":0,"snap_epoch":0,"pool_snaps":[],"removed_snaps":"[]","quota_max_bytes":0,"quota_max_objects":0,"tiers":[],"tier_of":-1,"read_tier":-1,"write_tier":-1,"cache_mode":"none","target_max_bytes":0,"target_max_objects":0,"cache_target_dirty_ratio_micro":400000,"cache_target_dirty_high_ratio_micro":600000,"cache_target_full_ratio_micro":800000,"cache_min_flush_age":0,"cache_min_evict_age":0,"erasure_code_profile":"","hit_set_params":{"type":"none"},"hit_set_period":0,"hit_set_count":0,"use_gmt_hitset":true,"min_read_recency_for_promote":0,"min_write_recency_for_promote":0,"hit_set_grade_decay_rate":0,"hit_set_search_last_n":0,"grade_table":[],"stripe_width":0,"expected_num_objects":0,"fast_read":false,"options":{},"application_metadata":{"cephfs":{"data":"cephfs"}},"read_balance":{"score_type":"Fair distribution","score_acting":2.5999999046325684,"score_stable":2.5999999046325684,"optimal_score":0.52999997138977051,"raw_score_acting":1.3799999952316284,"raw_score_stable":1.3799999952316284,"primary_affinity_weighted":1,"average_primary_affinity":1,"average_primary_affinity_weighted":1}},{"pool_id":5,"pool_name":".rgw.root","create_time":"2025-04-14T22:39:45.484609+0000","flags":1,"flags_names":"hashpspool","type":1,"size":3,"min_size":2,"crush_rule":0,"peering_crush_bucket_count":0,"peering_crush_bucket_target":0,"peering_crush_bucket_barrier":0,"peering_crush_bucket_mandatory_member":2147483647,"is_stretch_pool":false,"object_hash":2,"pg_autoscale_mode":"on","pg_num":32,"pg_placement_num":32,"pg_placement_num_target":32,"pg_num_target":32,"pg_num_pending":32,"last_pg_merge_meta":{"source_pgid":"0.0","ready_epoch":0,"last_epoch_started":0,"last_epoch_clean":0,"source_version":"0'0","target_version":"0'0"},"las
2025-04-15 00:05:51,046 - cephci - ceph:1186 - DEBUG - t_change":"134","last_force_op_resend":"0","last_force_op_resend_prenautilus":"0","last_force_op_resend_preluminous":"85","auid":0,"snap_mode":"selfmanaged","snap_seq":0,"snap_epoch":0,"pool_snaps":[],"removed_snaps":"[]","quota_max_bytes":0,"quota_max_objects":0,"tiers":[],"tier_of":-1,"read_tier":-1,"write_tier":-1,"cache_mode":"none","target_max_bytes":0,"target_max_objects":0,"cache_target_dirty_ratio_micro":400000,"cache_target_dirty_high_ratio_micro":600000,"cache_target_full_ratio_micro":800000,"cache_min_flush_age":0,"cache_min_evict_age":0,"erasure_code_profile":"","hit_set_params":{"type":"none"},"hit_set_period":0,"hit_set_count":0,"use_gmt_hitset":true,"min_read_recency_for_promote":0,"min_write_recency_for_promote":0,"hit_set_grade_decay_rate":0,"hit_set_search_last_n":0,"grade_table":[],"stripe_width":0,"expected_num_objects":0,"fast_read":false,"options":{},"application_metadata":{"rgw":{}},"read_balance":{"score_type":"Fair distribution","score_acting":3.2999999523162842,"score_stable":3.2999999523162842,"optimal_score":0.52999997138977051,"raw_score_acting":1.75,"raw_score_stable":1.75,"primary_affinity_weighted":1,"average_primary_affinity":1,"average_primary_affinity_weighted":1}},{"pool_id":6,"pool_name":"default.rgw.log","create_time":"2025-04-14T22:39:48.188823+0000","flags":1,"flags_names":"hashpspool","type":1,"size":3,"min_size":2,"crush_rule":0,"peering_crush_bucket_count":0,"peering_crush_bucket_target":0,"peering_crush_bucket_barrier":0,"peering_crush_bucket_mandatory_member":2147483647,"is_stretch_pool":false,"object_hash":2,"pg_autoscale_mode":"on","pg_num":32,"pg_placement_num":19,"pg_placement_num_target":32,"pg_num_target":32,"pg_num_pending":32,"last_pg_merge_meta":{"source_pgid":"0.0","ready_epoch":0,"last_epoch_started":0,"last_epoch_clean":0,"source_version":"0'0","target_version":"0'0"},"last_change":"259","last_force_op_resend":"0","last_force_op_resend_prenautilus":"0","last_force_op_resend_preluminous":"87","auid":0,"snap_mode":"selfmanaged","snap_seq":0,"snap_epoch":0,"po
2025-04-15 00:05:51,046 - cephci - ceph:1186 - DEBUG - ol_snaps":[],"removed_snaps":"[]","quota_max_bytes":0,"quota_max_objects":0,"tiers":[],"tier_of":-1,"read_tier":-1,"write_tier":-1,"cache_mode":"none","target_max_bytes":0,"target_max_objects":0,"cache_target_dirty_ratio_micro":400000,"cache_target_dirty_high_ratio_micro":600000,"cache_target_full_ratio_micro":800000,"cache_min_flush_age":0,"cache_min_evict_age":0,"erasure_code_profile":"","hit_set_params":{"type":"none"},"hit_set_period":0,"hit_set_count":0,"use_gmt_hitset":true,"min_read_recency_for_promote":0,"min_write_recency_for_promote":0,"hit_set_grade_decay_rate":0,"hit_set_search_last_n":0,"grade_table":[],"stripe_width":0,"expected_num_objects":0,"fast_read":false,"options":{},"application_metadata":{"rgw":{}},"read_balance":{"score_type":"Fair distribution","score_acting":5.190000057220459,"score_stable":5.190000057220459,"optimal_score":0.52999997138977051,"raw_score_acting":2.75,"raw_score_stable":2.75,"primary_affinity_weighted":1,"average_primary_affinity":1,"average_primary_affinity_weighted":1}},{"pool_id":7,"pool_name":"default.rgw.control","create_time":"2025-04-14T22:39:50.388024+0000","flags":1,"flags_names":"hashpspool","type":1,"size":3,"min_size":2,"crush_rule":0,"peering_crush_bucket_count":0,"peering_crush_bucket_target":0,"peering_crush_bucket_barrier":0,"peering_crush_bucket_mandatory_member":2147483647,"is_stretch_pool":false,"object_hash":2,"pg_autoscale_mode":"on","pg_num":32,"pg_placement_num":32,"pg_placement_num_target":32,"pg_num_target":32,"pg_num_pending":32,"last_pg_merge_meta":{"source_pgid":"0.0","ready_epoch":0,"last_epoch_started":0,"last_epoch_clean":0,"source_version":"0'0","target_version":"0'0"},"last_change":"134","last_force_op_resend":"0","last_force_op_resend_prenautilus":"0","last_force_op_resend_preluminous":"87","auid":0,"snap_mode":"selfmanaged","snap_seq":0,"snap_epoch":0,"pool_snaps":[],"removed_snaps":"[]","quota_max_bytes":0,"quota_max_objects":0,"tiers":[],"tier_of":-1,"read_tier":-1,"write_tier":-1,"cache_mode":"none","target_max_bytes":0,"target_max_ob
2025-04-15 00:05:51,047 - cephci - ceph:1186 - DEBUG - jects":0,"cache_target_dirty_ratio_micro":400000,"cache_target_dirty_high_ratio_micro":600000,"cache_target_full_ratio_micro":800000,"cache_min_flush_age":0,"cache_min_evict_age":0,"erasure_code_profile":"","hit_set_params":{"type":"none"},"hit_set_period":0,"hit_set_count":0,"use_gmt_hitset":true,"min_read_recency_for_promote":0,"min_write_recency_for_promote":0,"hit_set_grade_decay_rate":0,"hit_set_search_last_n":0,"grade_table":[],"stripe_width":0,"expected_num_objects":0,"fast_read":false,"options":{},"application_metadata":{"rgw":{}},"read_balance":{"score_type":"Fair distribution","score_acting":2.8299999237060547,"score_stable":2.8299999237060547,"optimal_score":0.52999997138977051,"raw_score_acting":1.5,"raw_score_stable":1.5,"primary_affinity_weighted":1,"average_primary_affinity":1,"average_primary_affinity_weighted":1}},{"pool_id":8,"pool_name":"default.rgw.meta","create_time":"2025-04-14T22:39:53.084405+0000","flags":1,"flags_names":"hashpspool","type":1,"size":3,"min_size":2,"crush_rule":0,"peering_crush_bucket_count":0,"peering_crush_bucket_target":0,"peering_crush_bucket_barrier":0,"peering_crush_bucket_mandatory_member":2147483647,"is_stretch_pool":false,"object_hash":2,"pg_autoscale_mode":"on","pg_num":32,"pg_placement_num":32,"pg_placement_num_target":32,"pg_num_target":32,"pg_num_pending":32,"last_pg_merge_meta":{"source_pgid":"0.0","ready_epoch":0,"last_epoch_started":0,"last_epoch_clean":0,"source_version":"0'0","target_version":"0'0"},"last_change":"134","last_force_op_resend":"0","last_force_op_resend_prenautilus":"0","last_force_op_resend_preluminous":"89","auid":0,"snap_mode":"selfmanaged","snap_seq":0,"snap_epoch":0,"pool_snaps":[],"removed_snaps":"[]","quota_max_bytes":0,"quota_max_objects":0,"tiers":[],"tier_of":-1,"read_tier":-1,"write_tier":-1,"cache_mode":"none","target_max_bytes":0,"target_max_objects":0,"cache_target_dirty_ratio_micro":400000,"cache_target_dirty_high_ratio_micro":600000,"cache_target_full_ratio_micro":800000,"cache_min_flush_age":0,"cache_min_evict_age":0,"erasure
2025-04-15 00:05:51,048 - cephci - ceph:1186 - DEBUG - _code_profile":"","hit_set_params":{"type":"none"},"hit_set_period":0,"hit_set_count":0,"use_gmt_hitset":true,"min_read_recency_for_promote":0,"min_write_recency_for_promote":0,"hit_set_grade_decay_rate":0,"hit_set_search_last_n":0,"grade_table":[],"stripe_width":0,"expected_num_objects":0,"fast_read":false,"options":{"pg_autoscale_bias":4},"application_metadata":{"rgw":{}},"read_balance":{"score_type":"Fair distribution","score_acting":2.3599998950958252,"score_stable":2.3599998950958252,"optimal_score":0.52999997138977051,"raw_score_acting":1.25,"raw_score_stable":1.25,"primary_affinity_weighted":1,"average_primary_affinity":1,"average_primary_affinity_weighted":1}},{"pool_id":10,"pool_name":"re_pool_concurrent_io","create_time":"2025-04-14T23:55:12.321593+0000","flags":1,"flags_names":"hashpspool","type":1,"size":3,"min_size":2,"crush_rule":0,"peering_crush_bucket_count":0,"peering_crush_bucket_target":0,"peering_crush_bucket_barrier":0,"peering_crush_bucket_mandatory_member":2147483647,"is_stretch_pool":false,"object_hash":2,"pg_autoscale_mode":"on","pg_num":32,"pg_placement_num":1,"pg_placement_num_target":32,"pg_num_target":32,"pg_num_pending":32,"last_pg_merge_meta":{"source_pgid":"0.0","ready_epoch":0,"last_epoch_started":0,"last_epoch_clean":0,"source_version":"0'0","target_version":"0'0"},"last_change":"283","last_force_op_resend":"0","last_force_op_resend_prenautilus":"0","last_force_op_resend_preluminous":"283","auid":0,"snap_mode":"selfmanaged","snap_seq":0,"snap_epoch":0,"pool_snaps":[],"removed_snaps":"[]","quota_max_bytes":0,"quota_max_objects":0,"tiers":[],"tier_of":-1,"read_tier":-1,"write_tier":-1,"cache_mode":"none","target_max_bytes":0,"target_max_objects":0,"cache_target_dirty_ratio_micro":400000,"cache_target_dirty_high_ratio_micro":600000,"cache_target_full_ratio_micro":800000,"cache_min_flush_age":0,"cache_min_evict_age":0,"erasure_code_profile":"","hit_set_params":{"type":"none"},"hit_set_period":0,"hit_set_count":0,"use_gmt_hitset":true,"min_read_recency_for_promote":0,"min_write_recenc
2025-04-15 00:05:51,048 - cephci - ceph:1186 - DEBUG - y_for_promote":0,"hit_set_grade_decay_rate":0,"hit_set_search_last_n":0,"grade_table":[],"stripe_width":0,"expected_num_objects":0,"fast_read":false,"options":{},"application_metadata":{"rados":{}},"read_balance":{"score_type":"Fair distribution","score_acting":14.289999961853027,"score_stable":14.289999961853027,"optimal_score":0.070000000298023224,"raw_score_acting":1,"raw_score_stable":1,"primary_affinity_weighted":1,"average_primary_affinity":1,"average_primary_affinity_weighted":1}}]
2025-04-15 00:05:51,050 - cephci - ceph:1576 - INFO - Execute ceph osd pool delete re_pool_concurrent_io re_pool_concurrent_io --yes-i-really-really-mean-it on 10.0.195.201
2025-04-15 00:05:53,056 - cephci - ceph:1606 - INFO - Execution of ceph osd pool delete re_pool_concurrent_io re_pool_concurrent_io --yes-i-really-really-mean-it on 10.0.195.201 took 2.005006 seconds
2025-04-15 00:05:55,061 - cephci - ceph:1576 - INFO - Execute ceph df -f json on 10.0.195.201
2025-04-15 00:05:56,066 - cephci - ceph:1606 - INFO - Execution of ceph df -f json on 10.0.195.201 took 1.004416 seconds
2025-04-15 00:05:56,066 - cephci - core_workflows:1199 - INFO - Pool:re_pool_concurrent_io deleted Successfully
2025-04-15 00:05:56,068 - cephci - ceph:1576 - INFO - Execute ceph config set mon mon_allow_pool_delete true on 10.0.195.201
2025-04-15 00:05:57,073 - cephci - ceph:1606 - INFO - Execution of ceph config set mon mon_allow_pool_delete true on 10.0.195.201 took 1.004203 seconds
2025-04-15 00:05:57,075 - cephci - ceph:1576 - INFO - Execute ceph df -f json on 10.0.195.201
2025-04-15 00:05:58,080 - cephci - ceph:1606 - INFO - Execution of ceph df -f json on 10.0.195.201 took 1.004219 seconds
2025-04-15 00:05:58,081 - cephci - core_workflows:1166 - ERROR - Pool:re_pool_parallel_io does not exist on cluster, cannot delete
2025-04-15 00:05:58,081 - cephci - core_workflows:4558 - DEBUG - Printing cluster health and status
2025-04-15 00:05:58,083 - cephci - ceph:1576 - INFO - Execute cephadm shell -- ceph health detail on 10.0.195.177
2025-04-15 00:06:00,837 - cephci - ceph:1606 - INFO - Execution of cephadm shell -- ceph health detail on 10.0.195.177 took 2.754073 seconds
2025-04-15 00:06:00,838 - cephci - shell:64 - DEBUG - HEALTH_WARN 9 OSD(s) experiencing slow operations in BlueStore; 1 failed cephadm daemon(s); 2 hosts fail cephadm check; 3 osds down; 1 host (5 osds) down; Reduced data availability: 202 pgs inactive, 41 pgs peering; Degraded data redundancy: 296/639 objects degraded (46.322%), 55 pgs degraded, 370 pgs undersized; 282 slow ops, oldest one blocked for 574 sec, daemons [osd.0,osd.2,osd.4,mon.ceph-regression-mfyctl-w265dr-node1-installer] have slow ops.
[WRN] BLUESTORE_SLOW_OP_ALERT: 9 OSD(s) experiencing slow operations in BlueStore
     osd.0 observed slow operation indications in BlueStore
     osd.4 observed slow operation indications in BlueStore
     osd.8 observed slow operation indications in BlueStore
     osd.9 observed slow operation indications in BlueStore
     osd.10 observed slow operation indications in BlueStore
     osd.11 observed slow operation indications in BlueStore
     osd.12 observed slow operation indications in BlueStore
     osd.13 observed slow operation indications in BlueStore
     osd.14 observed slow operation indications in BlueStore
[WRN] CEPHADM_FAILED_DAEMON: 1 failed cephadm daemon(s)
    daemon node-exporter.ceph-regression-mfyctl-w265dr-node1-installer on ceph-regression-mfyctl-w265dr-node1-installer is in error state
[WRN] CEPHADM_HOST_CHECK_FAILED: 2 hosts fail cephadm check
    host ceph-regression-mfyctl-w265dr-node5 (10.0.195.184) failed check: Failed to connect to ceph-regression-mfyctl-w265dr-node5 (10.0.195.184): TimeoutError()
Log: [conn=0, chan=612]   Command: which python3
[conn=10, chan=409]   Command: which python3
[conn=20, chan=414]   Command: which python3
[conn=30, chan=398]   Command: which python3
[conn=0, chan=612] Received exit status 0
[conn=0, chan=612] Received channel close
[conn=0, chan=612] Channel closed
[conn=0, chan=613] Requesting new SSH session
[conn=10, chan=409] Received exit status 0
[conn=10, chan=409] Received channel close
[conn=10, chan=409] Channel closed
[conn=0, chan=613]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=414] Received exit status 0
[conn=20, chan=414] Received channel close
[conn=30, chan=398] Received exit status 0
[conn=30, chan=398] Received channel close
[conn=10, chan=410] Requesting new SSH session
[conn=20, chan=414] Channel closed
[conn=30, chan=398] Channel closed
[conn=20, chan=415] Requesting new SSH session
[conn=30, chan=399] Requesting new SSH session
[conn=10, chan=410]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=415]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 check-host
[conn=30, chan=399]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 check-host
Opening SSH connection to 10.0.195.184, port 22
[conn=51] Connected to SSH server at 10.0.195.184, port 22
[conn=51]   Local address: 10.0.195.177, port 56330
[conn=51]   Peer address: 10.0.195.184, port 22
Opening SSH connection to 10.0.195.49, port 22
[conn=52] Connected to SSH server at 10.0.195.49, port 22
[conn=52]   Local address: 10.0.195.177, port 58770
[conn=52]   Peer address: 10.0.195.49, port 22
[conn=30, chan=399] Received exit status 0
[conn=30, chan=399] Received channel close
[conn=20, chan=415] Received exit status 0
[conn=20, chan=415] Received channel close
[conn=30, chan=399] Channel closed
[conn=20, chan=415] Channel closed
[conn=0, chan=613] Received exit status 0
[conn=0, chan=613] Received channel close
[conn=0, chan=613] Channel closed
[conn=10, chan=410] Received exit status 0
[conn=10, chan=410] Received channel close
[conn=10, chan=410] Channel closed
[conn=20, chan=416] Requesting new SSH session
[conn=20, chan=416]   Command: which python3
[conn=20, chan=416] Received exit status 0
[conn=20, chan=416] Received channel close
[conn=20, chan=416] Channel closed
[conn=30, chan=400] Requesting new SSH session
[conn=20, chan=417] Requesting new SSH session
[conn=30, chan=400]   Command: which python3
[conn=20, chan=417]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=30, chan=400] Received exit status 0
[conn=30, chan=400] Received channel close
[conn=30, chan=400] Channel closed
[conn=30, chan=401] Requesting new SSH session
[conn=30, chan=401]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=417] Received exit status 0
[conn=20, chan=417] Received channel close
[conn=20, chan=417] Channel closed
[conn=30, chan=401] Received exit status 0
[conn=30, chan=401] Received channel close
[conn=30, chan=401] Channel closed
[conn=51] Aborting connection
[conn=51] Connection closed

    host ceph-regression-mfyctl-w265dr-node3 (10.0.195.49) failed check: Failed to connect to ceph-regression-mfyctl-w265dr-node3 (10.0.195.49): TimeoutError()
Log: [conn=0, chan=612]   Command: which python3
[conn=10, chan=409]   Command: which python3
[conn=20, chan=414]   Command: which python3
[conn=30, chan=398]   Command: which python3
[conn=0, chan=612] Received exit status 0
[conn=0, chan=612] Received channel close
[conn=0, chan=612] Channel closed
[conn=0, chan=613] Requesting new SSH session
[conn=10, chan=409] Received exit status 0
[conn=10, chan=409] Received channel close
[conn=10, chan=409] Channel closed
[conn=0, chan=613]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=414] Received exit status 0
[conn=20, chan=414] Received channel close
[conn=30, chan=398] Received exit status 0
[conn=30, chan=398] Received channel close
[conn=10, chan=410] Requesting new SSH session
[conn=20, chan=414] Channel closed
[conn=30, chan=398] Channel closed
[conn=20, chan=415] Requesting new SSH session
[conn=30, chan=399] Requesting new SSH session
[conn=10, chan=410]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=415]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 check-host
[conn=30, chan=399]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 check-host
Opening SSH connection to 10.0.195.184, port 22
[conn=51] Connected to SSH server at 10.0.195.184, port 22
[conn=51]   Local address: 10.0.195.177, port 56330
[conn=51]   Peer address: 10.0.195.184, port 22
Opening SSH connection to 10.0.195.49, port 22
[conn=52] Connected to SSH server at 10.0.195.49, port 22
[conn=52]   Local address: 10.0.195.177, port 58770
[conn=52]   Peer address: 10.0.195.49, port 22
[conn=30, chan=399] Received exit status 0
[conn=30, chan=399] Received channel close
[conn=20, chan=415] Received exit status 0
[conn=20, chan=415] Received channel close
[conn=30, chan=399] Channel closed
[conn=20, chan=415] Channel closed
[conn=0, chan=613] Received exit status 0
[conn=0, chan=613] Received channel close
[conn=0, chan=613] Channel closed
[conn=10, chan=410] Received exit status 0
[conn=10, chan=410] Received channel close
[conn=10, chan=410] Channel closed
[conn=20, chan=416] Requesting new SSH session
[conn=20, chan=416]   Command: which python3
[conn=20, chan=416] Received exit status 0
[conn=20, chan=416] Received channel close
[conn=20, chan=416] Channel closed
[conn=30, chan=400] Requesting new SSH session
[conn=20, chan=417] Requesting new SSH session
[conn=30, chan=400]   Command: which python3
[conn=20, chan=417]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=30, chan=400] Received exit status 0
[conn=30, chan=400] Received channel close
[conn=30, chan=400] Channel closed
[conn=30, chan=401] Requesting new SSH session
[conn=30, chan=401]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=417] Received exit status 0
[conn=20, chan=417] Received channel close
[conn=20, chan=417] Channel closed
[conn=30, chan=401] Received exit status 0
[conn=30, chan=401] Received channel close
[conn=30, chan=401] Channel closed
[conn=51] Aborting connection
[conn=51] Connection closed
[conn=52] Aborting connection
[conn=52] Connection closed

[WRN] OSD_DOWN: 3 osds down
    osd.9 (root=default,host=ceph-regression-mfyctl-w265dr-node5) is down
    osd.12 (root=default,host=ceph-regression-mfyctl-w265dr-node3) is down
    osd.13 (root=default,host=ceph-regression-mfyctl-w265dr-node3) is down
[WRN] OSD_HOST_DOWN: 1 host (5 osds) down
    host ceph-regression-mfyctl-w265dr-node5 (root=default) (5 osds) is down
[WRN] PG_AVAILABILITY: Reduced data availability: 202 pgs inactive, 41 pgs peering
    pg 4.150 is stuck inactive for 8m, current state peering, last acting [0,10]
    pg 4.151 is stuck inactive for 63m, current state undersized+peered, last acting [4]
    pg 4.158 is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.15c is stuck peering for 11m, current state peering, last acting [0,11]
    pg 4.15e is stuck inactive for 11m, current state undersized+peered, last acting [2]
    pg 4.15f is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.161 is stuck inactive for 63m, current state undersized+peered, last acting [2]
    pg 4.167 is stuck inactive for 11m, current state undersized+peered, last acting [0]
    pg 4.16c is stuck inactive for 63m, current state undersized+peered, last acting [0]
    pg 4.171 is stuck inactive for 63m, current state undersized+peered, last acting [2]
    pg 4.172 is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.174 is stuck inactive for 11m, current state undersized+peered, last acting [0]
    pg 4.178 is stuck inactive for 11m, current state undersized+peered, last acting [6]
    pg 4.17d is stuck inactive for 63m, current state undersized+peered, last acting [2]
    pg 4.183 is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.185 is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.18b is stuck inactive for 11m, current state undersized+peered, last acting [0]
    pg 4.18c is stuck inactive for 11m, current state undersized+peered, last acting [2]
    pg 4.196 is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.199 is stuck peering for 11m, current state peering, last acting [0,11]
    pg 4.19a is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.19d is stuck peering for 11m, current state peering, last acting [0,11]
    pg 4.19f is stuck inactive for 55m, current state undersized+peered, last acting [2]
    pg 4.1a0 is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.1a4 is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.1a9 is stuck inactive for 11m, current state undersized+peered, last acting [2]
    pg 4.1ab is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.1b0 is stuck peering for 11m, current state peering, last acting [0,11]
    pg 4.1b5 is stuck peering for 11m, current state peering, last acting [0,10]
    pg 4.1b6 is stuck peering for 11m, current state peering, last acting [0,14]
    pg 4.1b9 is stuck inactive for 11m, current state undersized+peered, last acting [2]
    pg 4.1be is stuck inactive for 45m, current state undersized+peered, last acting [8]
    pg 4.1c4 is stuck inactive for 55m, current state undersized+peered, last acting [6]
    pg 4.1c8 is stuck peering for 11m, current state peering, last acting [0,10]
    pg 4.1cd is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.1d1 is stuck inactive for 11m, current state undersized+peered, last acting [6]
    pg 4.1d3 is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.1d4 is stuck inactive for 55m, current state undersized+peered, last acting [8]
    pg 4.1d8 is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.1dc is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.1dd is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.1e6 is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.1e7 is stuck peering for 11m, current state peering, last acting [0,11]
    pg 4.1eb is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.1ee is stuck inactive for 55m, current state undersized+peered, last acting [0]
    pg 4.1f1 is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.1f6 is stuck inactive for 11m, current state undersized+peered, last acting [6]
    pg 4.1f8 is stuck inactive for 11m, current state undersized+peered, last acting [2]
    pg 4.1f9 is stuck peering for 11m, current state peering, last acting [0,10]
    pg 4.1fa is stuck inactive for 55m, current state undersized+peered, last acting [8]
    pg 4.1fd is stuck inactive for 11m, current state undersized+peered, last acting [2]
[WRN] PG_DEGRADED: Degraded data redundancy: 296/639 objects degraded (46.322%), 55 pgs degraded, 370 pgs undersized
    pg 4.1a7 is stuck undersized for 11m, current state active+undersized, last acting [6,10]
    pg 4.1a8 is stuck undersized for 11m, current state active+undersized, last acting [14,0]
    pg 4.1aa is stuck undersized for 11m, current state active+undersized, last acting [10,4]
    pg 4.1ad is stuck undersized for 11m, current state active+undersized, last acting [14,0]
    pg 4.1ae is stuck undersized for 11m, current state active+undersized, last acting [2,14]
    pg 4.1af is stuck undersized for 11m, current state active+undersized, last acting [6,11]
    pg 4.1b1 is stuck undersized for 11m, current state active+undersized, last acting [8,11]
    pg 4.1b2 is stuck undersized for 11m, current state active+undersized, last acting [10,0]
    pg 4.1b3 is stuck undersized for 11m, current state active+undersized, last acting [2,10]
    pg 4.1b4 is stuck undersized for 11m, current state active+undersized, last acting [11,6]
    pg 4.1b7 is stuck undersized for 11m, current state active+undersized, last acting [2,14]
    pg 4.1b8 is stuck undersized for 11m, current state active+undersized, last acting [14,8]
    pg 4.1ba is stuck undersized for 11m, current state active+undersized, last acting [10,6]
    pg 4.1bc is stuck undersized for 11m, current state active+undersized, last acting [6,10]
    pg 4.1bd is stuck undersized for 11m, current state active+undersized, last acting [4,10]
    pg 4.1bf is stuck undersized for 11m, current state active+undersized, last acting [10,0]
    pg 4.1c0 is stuck undersized for 11m, current state active+undersized, last acting [11,6]
    pg 4.1c2 is stuck undersized for 11m, current state active+undersized, last acting [6,11]
    pg 4.1c3 is stuck undersized for 11m, current state active+undersized, last acting [11,0]
    pg 4.1c5 is stuck undersized for 11m, current state active+undersized, last acting [14,2]
    pg 4.1c9 is stuck undersized for 11m, current state active+undersized, last acting [4,14]
    pg 4.1ca is stuck undersized for 11m, current state active+undersized, last acting [6,11]
    pg 4.1cb is stuck undersized for 11m, current state active+undersized, last acting [14,6]
    pg 4.1cc is stuck undersized for 11m, current state active+undersized, last acting [8,11]
    pg 4.1ce is stuck undersized for 11m, current state active+undersized, last acting [14,0]
    pg 4.1cf is stuck undersized for 11m, current state active+undersized, last acting [8,11]
    pg 4.1d2 is stuck undersized for 11m, current state active+undersized, last acting [11,4]
    pg 4.1d5 is stuck undersized for 11m, current state active+undersized, last acting [11,8]
    pg 4.1d7 is stuck undersized for 11m, current state active+undersized, last acting [11,2]
    pg 4.1d9 is stuck undersized for 11m, current state active+undersized, last acting [4,14]
    pg 4.1da is stuck undersized for 11m, current state active+undersized, last acting [11,2]
    pg 4.1de is stuck undersized for 11m, current state active+undersized, last acting [8,10]
    pg 4.1df is stuck undersized for 11m, current state active+undersized, last acting [2,14]
    pg 4.1e0 is stuck undersized for 11m, current state active+undersized, last acting [8,10]
    pg 4.1e1 is stuck undersized for 11m, current state active+undersized, last acting [2,11]
    pg 4.1e2 is stuck undersized for 11m, current state active+undersized, last acting [10,4]
    pg 4.1e3 is stuck undersized for 11m, current state active+undersized, last acting [8,14]
    pg 4.1e4 is stuck undersized for 11m, current state active+undersized, last acting [14,6]
    pg 4.1e5 is stuck undersized for 11m, current state active+undersized, last acting [14,4]
    pg 4.1e8 is stuck undersized for 11m, current state active+undersized, last acting [2,10]
    pg 4.1ea is stuck undersized for 11m, current state active+undersized, last acting [14,8]
    pg 4.1ec is stuck undersized for 11m, current state active+undersized, last acting [10,8]
    pg 4.1f0 is stuck undersized for 11m, current state active+undersized, last acting [14,4]
    pg 4.1f3 is stuck undersized for 11m, current state active+undersized, last acting [11,0]
    pg 4.1f4 is stuck undersized for 11m, current state active+undersized, last acting [6,14]
    pg 4.1f5 is stuck undersized for 11m, current state active+undersized, last acting [8,14]
    pg 4.1f7 is stuck undersized for 11m, current state active+undersized, last acting [10,8]
    pg 4.1fb is stuck undersized for 11m, current state active+undersized, last acting [2,11]
    pg 4.1fc is stuck undersized for 11m, current state active+undersized, last acting [14,2]
    pg 4.1fe is stuck undersized for 11m, current state active+undersized, last acting [2,10]
    pg 4.1ff is stuck undersized for 11m, current state active+undersized, last acting [14,6]
[WRN] SLOW_OPS: 282 slow ops, oldest one blocked for 574 sec, daemons [osd.0,osd.2,osd.4,mon.ceph-regression-mfyctl-w265dr-node1-installer] have slow ops.

2025-04-15 00:06:00,842 - cephci - core_workflows:4560 - INFO - 
****
 Cluster health detail: 
 HEALTH_WARN 9 OSD(s) experiencing slow operations in BlueStore; 1 failed cephadm daemon(s); 2 hosts fail cephadm check; 3 osds down; 1 host (5 osds) down; Reduced data availability: 202 pgs inactive, 41 pgs peering; Degraded data redundancy: 296/639 objects degraded (46.322%), 55 pgs degraded, 370 pgs undersized; 282 slow ops, oldest one blocked for 574 sec, daemons [osd.0,osd.2,osd.4,mon.ceph-regression-mfyctl-w265dr-node1-installer] have slow ops.
[WRN] BLUESTORE_SLOW_OP_ALERT: 9 OSD(s) experiencing slow operations in BlueStore
     osd.0 observed slow operation indications in BlueStore
     osd.4 observed slow operation indications in BlueStore
     osd.8 observed slow operation indications in BlueStore
     osd.9 observed slow operation indications in BlueStore
     osd.10 observed slow operation indications in BlueStore
     osd.11 observed slow operation indications in BlueStore
     osd.12 observed slow operation indications in BlueStore
     osd.13 observed slow operation indications in BlueStore
     osd.14 observed slow operation indications in BlueStore
[WRN] CEPHADM_FAILED_DAEMON: 1 failed cephadm daemon(s)
    daemon node-exporter.ceph-regression-mfyctl-w265dr-node1-installer on ceph-regression-mfyctl-w265dr-node1-installer is in error state
[WRN] CEPHADM_HOST_CHECK_FAILED: 2 hosts fail cephadm check
    host ceph-regression-mfyctl-w265dr-node5 (10.0.195.184) failed check: Failed to connect to ceph-regression-mfyctl-w265dr-node5 (10.0.195.184): TimeoutError()
Log: [conn=0, chan=612]   Command: which python3
[conn=10, chan=409]   Command: which python3
[conn=20, chan=414]   Command: which python3
[conn=30, chan=398]   Command: which python3
[conn=0, chan=612] Received exit status 0
[conn=0, chan=612] Received channel close
[conn=0, chan=612] Channel closed
[conn=0, chan=613] Requesting new SSH session
[conn=10, chan=409] Received exit status 0
[conn=10, chan=409] Received channel close
[conn=10, chan=409] Channel closed
[conn=0, chan=613]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=414] Received exit status 0
[conn=20, chan=414] Received channel close
[conn=30, chan=398] Received exit status 0
[conn=30, chan=398] Received channel close
[conn=10, chan=410] Requesting new SSH session
[conn=20, chan=414] Channel closed
[conn=30, chan=398] Channel closed
[conn=20, chan=415] Requesting new SSH session
[conn=30, chan=399] Requesting new SSH session
[conn=10, chan=410]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=415]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 check-host
[conn=30, chan=399]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 check-host
Opening SSH connection to 10.0.195.184, port 22
[conn=51] Connected to SSH server at 10.0.195.184, port 22
[conn=51]   Local address: 10.0.195.177, port 56330
[conn=51]   Peer address: 10.0.195.184, port 22
Opening SSH connection to 10.0.195.49, port 22
[conn=52] Connected to SSH server at 10.0.195.49, port 22
[conn=52]   Local address: 10.0.195.177, port 58770
[conn=52]   Peer address: 10.0.195.49, port 22
[conn=30, chan=399] Received exit status 0
[conn=30, chan=399] Received channel close
[conn=20, chan=415] Received exit status 0
[conn=20, chan=415] Received channel close
[conn=30, chan=399] Channel closed
[conn=20, chan=415] Channel closed
[conn=0, chan=613] Received exit status 0
[conn=0, chan=613] Received channel close
[conn=0, chan=613] Channel closed
[conn=10, chan=410] Received exit status 0
[conn=10, chan=410] Received channel close
[conn=10, chan=410] Channel closed
[conn=20, chan=416] Requesting new SSH session
[conn=20, chan=416]   Command: which python3
[conn=20, chan=416] Received exit status 0
[conn=20, chan=416] Received channel close
[conn=20, chan=416] Channel closed
[conn=30, chan=400] Requesting new SSH session
[conn=20, chan=417] Requesting new SSH session
[conn=30, chan=400]   Command: which python3
[conn=20, chan=417]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=30, chan=400] Received exit status 0
[conn=30, chan=400] Received channel close
[conn=30, chan=400] Channel closed
[conn=30, chan=401] Requesting new SSH session
[conn=30, chan=401]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=417] Received exit status 0
[conn=20, chan=417] Received channel close
[conn=20, chan=417] Channel closed
[conn=30, chan=401] Received exit status 0
[conn=30, chan=401] Received channel close
[conn=30, chan=401] Channel closed
[conn=51] Aborting connection
[conn=51] Connection closed

    host ceph-regression-mfyctl-w265dr-node3 (10.0.195.49) failed check: Failed to connect to ceph-regression-mfyctl-w265dr-node3 (10.0.195.49): TimeoutError()
Log: [conn=0, chan=612]   Command: which python3
[conn=10, chan=409]   Command: which python3
[conn=20, chan=414]   Command: which python3
[conn=30, chan=398]   Command: which python3
[conn=0, chan=612] Received exit status 0
[conn=0, chan=612] Received channel close
[conn=0, chan=612] Channel closed
[conn=0, chan=613] Requesting new SSH session
[conn=10, chan=409] Received exit status 0
[conn=10, chan=409] Received channel close
[conn=10, chan=409] Channel closed
[conn=0, chan=613]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=414] Received exit status 0
[conn=20, chan=414] Received channel close
[conn=30, chan=398] Received exit status 0
[conn=30, chan=398] Received channel close
[conn=10, chan=410] Requesting new SSH session
[conn=20, chan=414] Channel closed
[conn=30, chan=398] Channel closed
[conn=20, chan=415] Requesting new SSH session
[conn=30, chan=399] Requesting new SSH session
[conn=10, chan=410]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=415]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 check-host
[conn=30, chan=399]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 check-host
Opening SSH connection to 10.0.195.184, port 22
[conn=51] Connected to SSH server at 10.0.195.184, port 22
[conn=51]   Local address: 10.0.195.177, port 56330
[conn=51]   Peer address: 10.0.195.184, port 22
Opening SSH connection to 10.0.195.49, port 22
[conn=52] Connected to SSH server at 10.0.195.49, port 22
[conn=52]   Local address: 10.0.195.177, port 58770
[conn=52]   Peer address: 10.0.195.49, port 22
[conn=30, chan=399] Received exit status 0
[conn=30, chan=399] Received channel close
[conn=20, chan=415] Received exit status 0
[conn=20, chan=415] Received channel close
[conn=30, chan=399] Channel closed
[conn=20, chan=415] Channel closed
[conn=0, chan=613] Received exit status 0
[conn=0, chan=613] Received channel close
[conn=0, chan=613] Channel closed
[conn=10, chan=410] Received exit status 0
[conn=10, chan=410] Received channel close
[conn=10, chan=410] Channel closed
[conn=20, chan=416] Requesting new SSH session
[conn=20, chan=416]   Command: which python3
[conn=20, chan=416] Received exit status 0
[conn=20, chan=416] Received channel close
[conn=20, chan=416] Channel closed
[conn=30, chan=400] Requesting new SSH session
[conn=20, chan=417] Requesting new SSH session
[conn=30, chan=400]   Command: which python3
[conn=20, chan=417]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=30, chan=400] Received exit status 0
[conn=30, chan=400] Received channel close
[conn=30, chan=400] Channel closed
[conn=30, chan=401] Requesting new SSH session
[conn=30, chan=401]   Command: /usr/bin/python3 /var/lib/ceph/bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf/cephadm.5032166f7ea98103e0e71f48bdd21f7fdb8516c696edabd4214a9c477b6198ba --timeout 895 gather-facts
[conn=20, chan=417] Received exit status 0
[conn=20, chan=417] Received channel close
[conn=20, chan=417] Channel closed
[conn=30, chan=401] Received exit status 0
[conn=30, chan=401] Received channel close
[conn=30, chan=401] Channel closed
[conn=51] Aborting connection
[conn=51] Connection closed
[conn=52] Aborting connection
[conn=52] Connection closed

[WRN] OSD_DOWN: 3 osds down
    osd.9 (root=default,host=ceph-regression-mfyctl-w265dr-node5) is down
    osd.12 (root=default,host=ceph-regression-mfyctl-w265dr-node3) is down
    osd.13 (root=default,host=ceph-regression-mfyctl-w265dr-node3) is down
[WRN] OSD_HOST_DOWN: 1 host (5 osds) down
    host ceph-regression-mfyctl-w265dr-node5 (root=default) (5 osds) is down
[WRN] PG_AVAILABILITY: Reduced data availability: 202 pgs inactive, 41 pgs peering
    pg 4.150 is stuck inactive for 8m, current state peering, last acting [0,10]
    pg 4.151 is stuck inactive for 63m, current state undersized+peered, last acting [4]
    pg 4.158 is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.15c is stuck peering for 11m, current state peering, last acting [0,11]
    pg 4.15e is stuck inactive for 11m, current state undersized+peered, last acting [2]
    pg 4.15f is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.161 is stuck inactive for 63m, current state undersized+peered, last acting [2]
    pg 4.167 is stuck inactive for 11m, current state undersized+peered, last acting [0]
    pg 4.16c is stuck inactive for 63m, current state undersized+peered, last acting [0]
    pg 4.171 is stuck inactive for 63m, current state undersized+peered, last acting [2]
    pg 4.172 is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.174 is stuck inactive for 11m, current state undersized+peered, last acting [0]
    pg 4.178 is stuck inactive for 11m, current state undersized+peered, last acting [6]
    pg 4.17d is stuck inactive for 63m, current state undersized+peered, last acting [2]
    pg 4.183 is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.185 is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.18b is stuck inactive for 11m, current state undersized+peered, last acting [0]
    pg 4.18c is stuck inactive for 11m, current state undersized+peered, last acting [2]
    pg 4.196 is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.199 is stuck peering for 11m, current state peering, last acting [0,11]
    pg 4.19a is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.19d is stuck peering for 11m, current state peering, last acting [0,11]
    pg 4.19f is stuck inactive for 55m, current state undersized+peered, last acting [2]
    pg 4.1a0 is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.1a4 is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.1a9 is stuck inactive for 11m, current state undersized+peered, last acting [2]
    pg 4.1ab is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.1b0 is stuck peering for 11m, current state peering, last acting [0,11]
    pg 4.1b5 is stuck peering for 11m, current state peering, last acting [0,10]
    pg 4.1b6 is stuck peering for 11m, current state peering, last acting [0,14]
    pg 4.1b9 is stuck inactive for 11m, current state undersized+peered, last acting [2]
    pg 4.1be is stuck inactive for 45m, current state undersized+peered, last acting [8]
    pg 4.1c4 is stuck inactive for 55m, current state undersized+peered, last acting [6]
    pg 4.1c8 is stuck peering for 11m, current state peering, last acting [0,10]
    pg 4.1cd is stuck inactive for 11m, current state undersized+peered, last acting [8]
    pg 4.1d1 is stuck inactive for 11m, current state undersized+peered, last acting [6]
    pg 4.1d3 is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.1d4 is stuck inactive for 55m, current state undersized+peered, last acting [8]
    pg 4.1d8 is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.1dc is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.1dd is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.1e6 is stuck inactive for 8m, current state undersized+peered, last acting [0]
    pg 4.1e7 is stuck peering for 11m, current state peering, last acting [0,11]
    pg 4.1eb is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.1ee is stuck inactive for 55m, current state undersized+peered, last acting [0]
    pg 4.1f1 is stuck inactive for 11m, current state undersized+peered, last acting [4]
    pg 4.1f6 is stuck inactive for 11m, current state undersized+peered, last acting [6]
    pg 4.1f8 is stuck inactive for 11m, current state undersized+peered, last acting [2]
    pg 4.1f9 is stuck peering for 11m, current state peering, last acting [0,10]
    pg 4.1fa is stuck inactive for 55m, current state undersized+peered, last acting [8]
    pg 4.1fd is stuck inactive for 11m, current state undersized+peered, last acting [2]
[WRN] PG_DEGRADED: Degraded data redundancy: 296/639 objects degraded (46.322%), 55 pgs degraded, 370 pgs undersized
    pg 4.1a7 is stuck undersized for 11m, current state active+undersized, last acting [6,10]
    pg 4.1a8 is stuck undersized for 11m, current state active+undersized, last acting [14,0]
    pg 4.1aa is stuck undersized for 11m, current state active+undersized, last acting [10,4]
    pg 4.1ad is stuck undersized for 11m, current state active+undersized, last acting [14,0]
    pg 4.1ae is stuck undersized for 11m, current state active+undersized, last acting [2,14]
    pg 4.1af is stuck undersized for 11m, current state active+undersized, last acting [6,11]
    pg 4.1b1 is stuck undersized for 11m, current state active+undersized, last acting [8,11]
    pg 4.1b2 is stuck undersized for 11m, current state active+undersized, last acting [10,0]
    pg 4.1b3 is stuck undersized for 11m, current state active+undersized, last acting [2,10]
    pg 4.1b4 is stuck undersized for 11m, current state active+undersized, last acting [11,6]
    pg 4.1b7 is stuck undersized for 11m, current state active+undersized, last acting [2,14]
    pg 4.1b8 is stuck undersized for 11m, current state active+undersized, last acting [14,8]
    pg 4.1ba is stuck undersized for 11m, current state active+undersized, last acting [10,6]
    pg 4.1bc is stuck undersized for 11m, current state active+undersized, last acting [6,10]
    pg 4.1bd is stuck undersized for 11m, current state active+undersized, last acting [4,10]
    pg 4.1bf is stuck undersized for 11m, current state active+undersized, last acting [10,0]
    pg 4.1c0 is stuck undersized for 11m, current state active+undersized, last acting [11,6]
    pg 4.1c2 is stuck undersized for 11m, current state active+undersized, last acting [6,11]
    pg 4.1c3 is stuck undersized for 11m, current state active+undersized, last acting [11,0]
    pg 4.1c5 is stuck undersized for 11m, current state active+undersized, last acting [14,2]
    pg 4.1c9 is stuck undersized for 11m, current state active+undersized, last acting [4,14]
    pg 4.1ca is stuck undersized for 11m, current state active+undersized, last acting [6,11]
    pg 4.1cb is stuck undersized for 11m, current state active+undersized, last acting [14,6]
    pg 4.1cc is stuck undersized for 11m, current state active+undersized, last acting [8,11]
    pg 4.1ce is stuck undersized for 11m, current state active+undersized, last acting [14,0]
    pg 4.1cf is stuck undersized for 11m, current state active+undersized, last acting [8,11]
    pg 4.1d2 is stuck undersized for 11m, current state active+undersized, last acting [11,4]
    pg 4.1d5 is stuck undersized for 11m, current state active+undersized, last acting [11,8]
    pg 4.1d7 is stuck undersized for 11m, current state active+undersized, last acting [11,2]
    pg 4.1d9 is stuck undersized for 11m, current state active+undersized, last acting [4,14]
    pg 4.1da is stuck undersized for 11m, current state active+undersized, last acting [11,2]
    pg 4.1de is stuck undersized for 11m, current state active+undersized, last acting [8,10]
    pg 4.1df is stuck undersized for 11m, current state active+undersized, last acting [2,14]
    pg 4.1e0 is stuck undersized for 11m, current state active+undersized, last acting [8,10]
    pg 4.1e1 is stuck undersized for 11m, current state active+undersized, last acting [2,11]
    pg 4.1e2 is stuck undersized for 11m, current state active+undersized, last acting [10,4]
    pg 4.1e3 is stuck undersized for 11m, current state active+undersized, last acting [8,14]
    pg 4.1e4 is stuck undersized for 11m, current state active+undersized, last acting [14,6]
    pg 4.1e5 is stuck undersized for 11m, current state active+undersized, last acting [14,4]
    pg 4.1e8 is stuck undersized for 11m, current state active+undersized, last acting [2,10]
    pg 4.1ea is stuck undersized for 11m, current state active+undersized, last acting [14,8]
    pg 4.1ec is stuck undersized for 11m, current state active+undersized, last acting [10,8]
    pg 4.1f0 is stuck undersized for 11m, current state active+undersized, last acting [14,4]
    pg 4.1f3 is stuck undersized for 11m, current state active+undersized, last acting [11,0]
    pg 4.1f4 is stuck undersized for 11m, current state active+undersized, last acting [6,14]
    pg 4.1f5 is stuck undersized for 11m, current state active+undersized, last acting [8,14]
    pg 4.1f7 is stuck undersized for 11m, current state active+undersized, last acting [10,8]
    pg 4.1fb is stuck undersized for 11m, current state active+undersized, last acting [2,11]
    pg 4.1fc is stuck undersized for 11m, current state active+undersized, last acting [14,2]
    pg 4.1fe is stuck undersized for 11m, current state active+undersized, last acting [2,10]
    pg 4.1ff is stuck undersized for 11m, current state active+undersized, last acting [14,6]
[WRN] SLOW_OPS: 282 slow ops, oldest one blocked for 574 sec, daemons [osd.0,osd.2,osd.4,mon.ceph-regression-mfyctl-w265dr-node1-installer] have slow ops.
 
****
2025-04-15 00:06:00,846 - cephci - ceph:1576 - INFO - Execute ceph -s on 10.0.195.201
2025-04-15 00:06:01,851 - cephci - ceph:1606 - INFO - Execution of ceph -s on 10.0.195.201 took 1.003941 seconds
2025-04-15 00:06:01,851 - cephci - core_workflows:4561 - INFO - 
****
 Cluster status: 
   cluster:
    id:     bfe6bdbc-197e-11f0-a0a3-fa163e4fa5cf
    health: HEALTH_WARN
            9 OSD(s) experiencing slow operations in BlueStore
            1 failed cephadm daemon(s)
            2 hosts fail cephadm check
            3 osds down
            1 host (5 osds) down
            Reduced data availability: 202 pgs inactive, 41 pgs peering
            Degraded data redundancy: 296/639 objects degraded (46.322%), 55 pgs degraded, 370 pgs undersized
            282 slow ops, oldest one blocked for 574 sec, daemons [osd.0,osd.2,osd.4,mon.ceph-regression-mfyctl-w265dr-node1-installer] have slow ops.
 
  services:
    mon: 3 daemons, quorum ceph-regression-mfyctl-w265dr-node1-installer,ceph-regression-mfyctl-w265dr-node6,ceph-regression-mfyctl-w265dr-node2 (age 93m)
    mgr: ceph-regression-mfyctl-w265dr-node1-installer.xdzcdu(active, since 102m), standbys: ceph-regression-mfyctl-w265dr-node6.mrjkhg, ceph-regression-mfyctl-w265dr-node2.yzdorn
    mds: 1/1 daemons up, 1 standby
    osd: 15 osds: 8 up (since 14s), 11 in (since 79s); 1 remapped pgs
    rgw: 2 daemons active (2 hosts, 1 zones)
 
  data:
    volumes: 1/1 healthy
    pools:   8 pools, 689 pgs
    objects: 213 objects, 457 KiB
    usage:   6.7 GiB used, 268 GiB / 275 GiB avail
    pgs:     46.154% pgs not active
             296/639 objects degraded (46.322%)
             8/639 objects misplaced (1.252%)
             337 active+undersized
             254 undersized+peered
             41  peering
             27  active+undersized+degraded
             23  undersized+degraded+peered
             5   active+undersized+degraded+laggy
             1   active+undersized+laggy
             1   active+undersized+remapped
 
  progress:
    Global Recovery Event (102m)
      [............................] (remaining: 6w)
 
 
****
2025-04-15 00:06:01,854 - cephci - ceph:1576 - INFO - Execute cephadm shell -- ceph crash ls-new -f json on 10.0.195.177
2025-04-15 00:06:03,447 - cephci - ceph:1606 - INFO - Execution of cephadm shell -- ceph crash ls-new -f json on 10.0.195.177 took 1.592599 seconds
2025-04-15 00:06:03,447 - cephci - ceph:1186 - DEBUG - 
2025-04-15 00:06:03,448 - cephci - ceph:1186 - DEBUG - []
2025-04-15 00:06:03,489 - cephci - ceph:1576 - INFO - Execute podman --version | awk {'print $3'} on 10.0.195.177
2025-04-15 00:06:04,493 - cephci - ceph:1606 - INFO - Execution of podman --version | awk {'print $3'} on 10.0.195.177 took 1.003715 seconds
2025-04-15 00:06:04,494 - cephci - run:1065 - INFO - Podman Version 5.2.2
2025-04-15 00:06:04,496 - cephci - ceph:1576 - INFO - Execute docker --version | awk {'print $3'} on 10.0.195.177
2025-04-15 00:06:05,500 - cephci - ceph:1606 - INFO - Execution of docker --version | awk {'print $3'} on 10.0.195.177 took 1.003758 seconds
2025-04-15 00:06:05,503 - cephci - ceph:1576 - INFO - Execute ceph --version | awk '{print $3}' on 10.0.195.201
2025-04-15 00:06:06,508 - cephci - ceph:1606 - INFO - Execution of ceph --version | awk '{print $3}' on 10.0.195.201 took 1.004787 seconds
2025-04-15 00:06:06,509 - cephci - run:1081 - INFO - ceph Version 19.2.1-126.el9cp
2025-04-15 00:06:06,511 - cephci - run:1040 - INFO - ceph_clusters_file rerun/regression-MFYctl-W265DR
2025-04-15 00:06:06,511 - cephci - run:927 - INFO - Test <module 'test_object_ops' from '/home/jenkins/ceph-builds/openstack/IBM/8.1/rhel-9/Regression/19.2.1-126/rados/99/cephci/tests/rados/test_object_ops.py'> failed
